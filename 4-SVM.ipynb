{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f303ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# SVM class for Classification and Regression\n",
    "# Kernal functions for SVM \n",
    "# It will be used for classification and regression \n",
    "# Linear Kernel\n",
    "def linear_kernel(x1, x2):\n",
    "    return np.dot(x1, x2)   \n",
    "\n",
    "# Polynomial Kernel\n",
    "def polynomial_kernel(x1, x2 , gamma=1, degree=3, coef0=1):\n",
    "    return ((gamma * np.dot(x1, x2)) + coef0) ** degree\n",
    "\n",
    "# Radial Basis Function (RBF) Kernel \n",
    "def rbf_kernel(x1, x2, gamma=1):\n",
    "    distance = np.linalg.norm(x1 - x2) ** 2\n",
    "    # Know that gamm = 1 / (2 * sigma^2)      \n",
    "    return np.exp(-gamma * distance)\n",
    "\n",
    "# Sigmoid Kernel\n",
    "def sigmoid_kernel(x1, x2, gamma=0.01, coef0=0):\n",
    "    return np.tanh((gamma * np.dot(x1, x2)) + coef0)\n",
    "\n",
    "# Classification and Regression using SVM\n",
    "# Classification class\n",
    "class SVC():\n",
    "\n",
    "    # Initialization\n",
    "    # Tol is threshold for stopping criteria \n",
    "    def __init__(self, c = 1.0, kernel = 'Linear', degree=3, gamma=1, coef0=1, tol=1e-3, max_iter=1000, decision_function_shape='ovr'):\n",
    "        self.c = c\n",
    "        self.degree = degree\n",
    "        self.gamma = gamma\n",
    "        self.coef0 = coef0\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.decision_function_shape = decision_function_shape\n",
    "        self.models = [] # To store sub-models for multiclass\n",
    "        self.classes = None\n",
    "        \n",
    "        # For each case of kernal is assigned by the retun value of the function to the varaibale kernal and assign the all parameters\n",
    "        # We make varaible as function \n",
    "        if kernel == 'Linear':\n",
    "            self.kernel = lambda x1, x2: linear_kernel(x1, x2)\n",
    "\n",
    "        elif kernel == 'Polynomial':\n",
    "            self.kernel = lambda x1, x2: polynomial_kernel(x1, x2, gamma=self.gamma, degree=self.degree, coef0=self.coef0)    \n",
    "\n",
    "        elif kernel == 'RBF':\n",
    "            self.kernel = lambda x1, x2: rbf_kernel(x1, x2, gamma=self.gamma)\n",
    "\n",
    "        elif kernel == 'Sigmoid':\n",
    "            self.kernel = lambda x1, x2: sigmoid_kernel(x1, x2, gamma=self.gamma, coef0=self.coef0)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unknown kernel.\")    \n",
    "\n",
    "    # Internal helper for binary training (SMO)\n",
    "    def _fit_binary(self, X, y):\n",
    "        m, n = X.shape\n",
    "        theta = np.zeros(m)\n",
    "        b = 0\n",
    "\n",
    "        # Compute the Kernel matrix\n",
    "        K_matrix = np.zeros((m, m))\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "                K_matrix[i, j] = self.kernel(X[i], X[j])   \n",
    "\n",
    "        # SMO Algorithm\n",
    "        for iteration in range(self.max_iter):      \n",
    "            alpha_prev = np.copy(theta)\n",
    "\n",
    "            for i in range(m):\n",
    "                f_xi = np.sum(theta * y * K_matrix[:, i]) + b\n",
    "                E_i = f_xi - y[i]\n",
    "\n",
    "                if (y[i] * E_i < -self.tol and theta[i] < self.c) or (y[i] * E_i > self.tol and theta[i] > 0):\n",
    "                    j = np.random.randint(0, m)\n",
    "                    while j == i:\n",
    "                        j = np.random.randint(0, m)\n",
    "\n",
    "                    f_xj = np.sum(theta * y * K_matrix[:, j]) + b\n",
    "                    E_j = f_xj - y[j]\n",
    "\n",
    "                    alpha_i_old, alpha_j_old = theta[i], theta[j]\n",
    "\n",
    "                    if y[i] != y[j]:\n",
    "                        L, H = max(0, alpha_j_old - alpha_i_old), min(self.c, self.c + alpha_j_old - alpha_i_old)\n",
    "                    else:\n",
    "                        L, H = max(0, alpha_i_old + alpha_j_old - self.c), min(self.c, alpha_i_old + alpha_j_old)\n",
    "\n",
    "                    if L == H: continue\n",
    "\n",
    "                    eta = 2.0 * K_matrix[i, j] - K_matrix[i, i] - K_matrix[j, j]\n",
    "                    if eta >= 0: continue\n",
    "\n",
    "                    theta[j] -= (y[j] * (E_i - E_j)) / eta\n",
    "                    theta[j] = np.clip(theta[j], L, H)\n",
    "\n",
    "                    if abs(theta[j] - alpha_j_old) < 1e-5: continue\n",
    "\n",
    "                    theta[i] += y[i] * y[j] * (alpha_j_old - theta[j])\n",
    "\n",
    "                    b1 = b - E_i - y[i] * (theta[i] - alpha_i_old) * K_matrix[i, i] - y[j] * (theta[j] - alpha_j_old) * K_matrix[i, j]   \n",
    "                    b2 = b - E_j - y[i] * (theta[i] - alpha_i_old) * K_matrix[i, j] - y[j] * (theta[j] - alpha_j_old) * K_matrix[j, j]\n",
    "\n",
    "                    if 0 < theta[i] < self.c: b = b1\n",
    "                    elif 0 < theta[j] < self.c: b = b2\n",
    "                    else: b = (b1 + b2) / 2\n",
    "\n",
    "            if np.linalg.norm(theta - alpha_prev) < self.tol:\n",
    "                break\n",
    "        \n",
    "        return {\"theta\": theta, \"b\": b, \"X\": X, \"y\": y}\n",
    "    \n",
    "    # Fit \n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        n_classes = len(self.classes)\n",
    "        self.models = []\n",
    "\n",
    "        if n_classes <= 2:\n",
    "            binary_y = np.where(y == self.classes[0], -1, 1)\n",
    "            self.models.append(self._fit_binary(X, binary_y))\n",
    "            \n",
    "        elif self.decision_function_shape == 'ovr':\n",
    "            # One vs Rest\n",
    "            for c in self.classes:\n",
    "                binary_y = np.where(y == c, 1, -1)\n",
    "                self.models.append(self._fit_binary(X, binary_y))\n",
    "\n",
    "        elif self.decision_function_shape == 'ovo':\n",
    "            # One vs One\n",
    "            for i in range(n_classes):\n",
    "                for j in range(i + 1, n_classes):\n",
    "                    idx = np.where((y == self.classes[i]) | (y == self.classes[j]))\n",
    "                    X_sub, y_sub = X[idx], y[idx]\n",
    "                    binary_y = np.where(y_sub == self.classes[i], 1, -1)\n",
    "                    model = self._fit_binary(X_sub, binary_y)\n",
    "                    model['cls_pair'] = (self.classes[i], self.classes[j])\n",
    "                    self.models.append(model)\n",
    "        \n",
    "        # Bias value and other theta values \n",
    "        self.intercept_ = self.models[0]['b']   \n",
    "        self.coef_ = self.models[0]['theta']         \n",
    "\n",
    "    # Decision function for a single model\n",
    "    def _get_score(self, X, model):\n",
    "        scores = []\n",
    "        for x in X:\n",
    "            score = np.sum(model['theta'] * model['y'] * [self.kernel(x_tr, x) for x_tr in model['X']]) + model['b']\n",
    "            scores.append(score)\n",
    "        return np.array(scores)\n",
    "\n",
    "    # Predict             \n",
    "    def predict(self, X):\n",
    "        if len(self.classes) <= 2:\n",
    "            scores = self._get_score(X, self.models[0])\n",
    "            return np.where(scores >= 0, self.classes[1], self.classes[0])\n",
    "\n",
    "        if self.decision_function_shape == 'ovr':\n",
    "            # Highest confidence wins\n",
    "            all_scores = np.array([self._get_score(X, m) for m in self.models])\n",
    "            return self.classes[np.argmax(all_scores, axis=0)]\n",
    "\n",
    "        elif self.decision_function_shape == 'ovo':\n",
    "            # Voting system\n",
    "            votes = np.zeros((len(X), len(self.classes)))\n",
    "            for m in self.models:\n",
    "                scores = self._get_score(X, m)\n",
    "                preds = np.where(scores >= 0, m['cls_pair'][0], m['cls_pair'][1])\n",
    "                for idx, p in enumerate(preds):\n",
    "                    votes[idx, np.where(self.classes == p)[0][0]] += 1\n",
    "            return self.classes[np.argmax(votes, axis=1)]\n",
    "\n",
    "    # Score \n",
    "    def score(self, X_new, y):\n",
    "        # Return accuracy score of the model\n",
    "        y_pred = self.predict(X_new)\n",
    "        return np.mean(y_pred == y) \n",
    "\n",
    "# Regression remains largely the same but usually doesn't use OVO/OVR\n",
    "class SVR():\n",
    "    def __init__(self, c=1.0, epsilon=0.1, kernel='Linear', degree=3, gamma=1, coef0=1, lr=0.001, max_iter=1000):\n",
    "        self.c = c\n",
    "        self.epsilon = epsilon\n",
    "        self.degree = degree\n",
    "        self.gamma = gamma\n",
    "        self.coef0 = coef0\n",
    "        self.lr = lr\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "        if kernel == 'Linear':\n",
    "            self.kernel = lambda x1, x2: linear_kernel(x1, x2)\n",
    "        elif kernel == 'Polynomial':\n",
    "            self.kernel = lambda x1, x2: polynomial_kernel(x1, x2, gamma=self.gamma, degree=self.degree, coef0=self.coef0)\n",
    "        elif kernel == 'RBF':\n",
    "            self.kernel = lambda x1, x2: rbf_kernel(x1, x2, gamma=self.gamma)\n",
    "        elif kernel == 'Sigmoid':\n",
    "            self.kernel = lambda x1, x2: sigmoid_kernel(x1, x2, gamma=self.gamma, coef0=self.coef0)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown kernel.\")\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        m = len(X)\n",
    "        self.alpha = np.zeros(m)\n",
    "        self.b = 0\n",
    "\n",
    "        self.K_matrix = np.zeros((m, m))\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "                self.K_matrix[i, j] = self.kernel(X[i], X[j])\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            for i in range(m):\n",
    "                pred = np.sum(self.alpha * self.K_matrix[:, i]) + self.b\n",
    "                error = pred - self.y[i]\n",
    "                if abs(error) > self.epsilon:\n",
    "                    self.alpha[i] -= self.lr * error\n",
    "                    self.alpha[i] = np.clip(self.alpha[i], -self.c, self.c)\n",
    "                    self.b -= self.lr * error\n",
    "\n",
    "        # Bias value and other theta values \n",
    "        self.intercept_ = self.b\n",
    "        self.coef_ = self.alpha            \n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            pred = np.sum(self.alpha * [self.kernel(x_tr, x) for x_tr in self.X]) + self.b\n",
    "            predictions.append(pred)\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def score(self, X_new, y):\n",
    "        # Return R^2 score \n",
    "        y_pred = self.predict(X_new)\n",
    "        ss_total = np.sum((y - np.mean(y)) ** 2)\n",
    "        ss_residual = np.sum((y - y_pred) ** 2)\n",
    "        return 1 - ss_residual / ss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51af1121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: SVC (Linear)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [0 1 1]\n",
      "Accuracy score on training data: 86.00 %\n",
      "Intercept: -2.13\n",
      "Coefficient: [ 0.    1.    1.    1.    1.   -0.    1.    0.    0.    1.    0.    0.\n",
      "  1.    1.    0.65  0.    1.    0.    1.    0.    0.09  1.    1.    0.\n",
      "  0.    0.    0.    1.    1.    0.    0.74  0.14  0.    1.    1.    1.\n",
      "  1.    0.    1.    0.    0.    1.    1.    1.    0.    0.    0.    0.\n",
      "  1.    0.    0.58  1.    0.    1.    0.    0.    1.    0.13  0.    0.\n",
      "  0.    0.    0.    0.    0.    0.97  0.    0.41  0.    0.28  1.    0.28\n",
      "  0.    1.    0.36 -0.    0.13  1.    0.    0.    0.    1.    1.    0.\n",
      "  0.    1.    0.    0.    1.    0.    0.   -0.   -0.    1.    0.    1.\n",
      "  0.    0.    0.    0.  ]\n",
      "\n",
      "----------------------------------------\n",
      "Method: SVC (Polynomial)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [1 1 1]\n",
      "Accuracy score on training data: 87.00 %\n",
      "Intercept: -1.62\n",
      "Coefficient: [ 0.    1.    1.    1.    1.    0.3   0.69  0.    0.    0.99  0.    0.\n",
      "  0.12  1.    0.03  0.    1.    0.    1.    0.    0.18  1.    1.    0.\n",
      "  0.    0.    0.    1.    1.    0.    0.04  0.    0.    0.43  1.    0.83\n",
      "  0.4   0.    1.    0.    0.    1.    1.    1.    0.    0.    0.    0.\n",
      "  1.    0.    0.38  0.68  0.    1.    0.    0.    0.23  0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.9   0.    0.    0.    0.    1.    0.\n",
      "  0.    1.    0.    0.    0.    1.    0.    0.    0.    1.    0.93  0.\n",
      "  0.    1.    0.    0.    1.    0.    0.    0.   -0.    1.   -0.    1.\n",
      "  0.    0.    0.    0.68]\n",
      "\n",
      "----------------------------------------\n",
      "Method: SVC (RBF)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [0 1 1]\n",
      "Accuracy score on training data: 87.00 %\n",
      "Intercept: 0.24\n",
      "Coefficient: [ 0.    1.    1.    1.    1.    1.    1.    0.    0.    1.    0.    0.\n",
      "  1.    1.    1.    0.    1.    0.    1.    0.    1.    1.    1.    0.\n",
      "  0.    0.    0.    1.    1.    0.    0.35  0.    0.    0.54  1.    1.\n",
      "  1.   -0.    1.    0.13  0.    1.    1.    1.    0.    0.    0.33  0.\n",
      "  1.    0.    1.    1.    0.    1.    0.    0.    1.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    1.    0.   -0.    0.    0.12  1.    0.17\n",
      "  0.    1.    0.16  0.    0.01  1.    0.    0.    0.    1.    1.    0.\n",
      "  0.    1.    0.    0.    1.    0.   -0.   -0.   -0.    1.    0.    1.\n",
      "  0.    0.    0.    0.78]\n",
      "\n",
      "----------------------------------------\n",
      "Method: SVC (Sigmoid)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [0 0 0]\n",
      "Accuracy score on training data: 48.00 %\n",
      "Intercept: -1.58\n",
      "Coefficient: [1.   1.   1.   1.   1.   1.   1.   0.   0.   1.   0.   1.   1.   1.\n",
      " 1.   0.   1.   0.   1.   1.   1.   1.   1.   1.   1.   1.   1.   0.\n",
      " 0.   0.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      " 1.   1.   0.   0.   1.   1.   1.   1.   1.   0.   1.   1.   1.   1.\n",
      " 0.   1.   1.   1.   1.   0.75 1.   0.   0.   1.   0.   1.   1.   1.\n",
      " 1.   0.25 0.   1.   0.   1.   1.   1.   1.   1.   0.   1.   1.   1.\n",
      " 1.   1.   0.   1.   1.   1.   1.   1.   1.   0.   0.   1.   0.   1.\n",
      " 0.   1.  ]\n",
      "\n",
      "----------------------------------------\n",
      "Method: SVC (Linear)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [0 2 2]\n",
      "Accuracy score on training data: 40.00 %\n",
      "Intercept: 1.98\n",
      "Coefficient: [0.   1.   0.7  0.   0.58 0.   0.   0.   0.   1.   0.   0.   0.   0.\n",
      " 1.   1.   0.96 0.   0.86 1.   1.   1.   0.   0.   1.   0.   1.   1.\n",
      " 1.   1.   1.   0.   0.   1.   1.   1.   1.   0.   1.   0.   0.   1.\n",
      " 1.   1.   0.   0.   0.   0.   1.   0.   1.   0.   0.   1.   0.   0.\n",
      " 0.   1.   1.   0.   0.   0.   0.   0.   0.   0.75 0.   1.   1.   1.\n",
      " 0.   0.   0.   1.   0.   0.   0.   1.   0.   0.   0.37 0.06 0.73 1.\n",
      " 0.   1.   0.99 0.   1.   0.   0.   0.   0.   1.   0.   1.   0.   0.\n",
      " 0.34 0.93]\n",
      "\n",
      "----------------------------------------\n",
      "Method: SVC (Polynomial)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [1 2 2]\n",
      "Accuracy score on training data: 42.00 %\n",
      "Intercept: 1.62\n",
      "Coefficient: [ 0.    1.    1.    0.    0.    0.    0.    0.    0.36  1.    0.    0.\n",
      "  0.    0.    1.    1.    1.    0.    1.    1.    0.99  1.    0.    0.\n",
      "  1.    0.    1.    0.    1.    1.    1.    0.    0.    1.    1.    1.\n",
      "  1.    0.    0.94  0.    0.    1.    1.    1.    0.    0.    0.    0.\n",
      "  1.    0.    1.    0.    0.    1.    0.    0.    0.    1.    0.    0.\n",
      "  0.    0.    0.    0.    0.   -0.    0.    0.89  1.    0.99  0.    0.\n",
      "  0.    1.    0.    0.    0.    1.    0.    0.    0.    0.42  0.    0.\n",
      "  0.    0.76  0.    0.    1.    0.21  0.    0.    0.    1.    0.    1.\n",
      "  0.    0.74  0.    0.95]\n",
      "\n",
      "----------------------------------------\n",
      "Method: SVC (RBF)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [1 2 2]\n",
      "Accuracy score on training data: 40.00 %\n",
      "Intercept: -0.41\n",
      "Coefficient: [0.   1.   1.   0.   1.   0.   0.   0.   0.   1.   0.36 0.   0.82 0.\n",
      " 1.   1.   0.43 0.   1.   1.   1.   1.   0.   0.   1.   0.   1.   0.87\n",
      " 0.59 1.   1.   0.   0.   1.   1.   1.   1.   0.   1.   0.   0.   1.\n",
      " 1.   1.   0.   0.   0.   0.   1.   0.   1.   0.   0.   1.   0.   0.\n",
      " 0.   1.   0.09 0.   0.52 0.   0.   0.   0.   0.   0.   1.   1.   1.\n",
      " 0.   0.   0.   1.   0.   0.   0.   1.   0.   0.   0.61 1.   1.   0.\n",
      " 0.   0.86 0.   0.   1.   1.   0.   0.   1.   1.   0.   1.   0.   1.\n",
      " 0.   1.  ]\n",
      "\n",
      "----------------------------------------\n",
      "Method: SVC (Sigmoid)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [0 0 0]\n",
      "Accuracy score on training data: 60.00 %\n",
      "Intercept: 0.02\n",
      "Coefficient: [1.   1.   0.   1.   1.   1.   1.   0.   1.   1.   1.   0.   1.   1.\n",
      " 1.   1.   0.   0.   1.   1.   1.   0.   0.04 1.   1.   0.   1.   0.\n",
      " 0.   1.   1.   1.   0.   1.   1.   1.   1.   0.   1.   0.   1.   1.\n",
      " 1.   1.   1.   0.   0.   0.   1.   1.   1.   0.   1.   1.   0.   1.\n",
      " 0.96 1.   1.   1.   1.   0.   1.   0.   0.   0.   0.   1.   1.   1.\n",
      " 0.   1.   0.   1.   0.   1.   0.   1.   0.   0.   1.   1.   1.   1.\n",
      " 0.   0.   1.   1.   1.   1.   0.   0.   1.   1.   1.   1.   0.   1.\n",
      " 1.   1.  ]\n",
      "\n",
      "----------------------------------------\n",
      "Method: SVC (Linear)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [1 2 2]\n",
      "Accuracy score on training data: 33.00 %\n",
      "Intercept: 0.74\n",
      "Coefficient: [0.   1.   1.   0.08 1.   0.   0.   1.   1.   0.   0.   1.   1.   0.45\n",
      " 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   0.   0.   1.   1.\n",
      " 1.   1.   0.   1.   1.   1.   1.   0.   1.   0.   1.   0.   1.   0.65\n",
      " 0.   0.   1.   1.   1.   0.   1.   0.   1.   0.37 0.73 1.   0.   1.\n",
      " 1.   1.   0.16 1.   1.   0.   1.   0.   0.   0.07]\n",
      "\n",
      "----------------------------------------\n",
      "Method: SVC (Polynomial)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [1 2 2]\n",
      "Accuracy score on training data: 45.00 %\n",
      "Intercept: 1.06\n",
      "Coefficient: [0.   1.   1.   0.   0.11 0.   0.   0.1  1.   0.   0.   1.   1.   1.\n",
      " 1.   1.   1.   1.   0.61 1.   0.   1.   1.   1.   0.   0.   1.   1.\n",
      " 1.   1.   0.   1.   1.   1.   1.   0.   1.   0.01 1.   0.   1.   0.06\n",
      " 0.   0.   1.   1.   1.   0.   1.   0.   1.   0.   0.78 0.32 0.   0.51\n",
      " 0.   1.   0.74 0.19 1.   0.   1.   0.02 0.   1.  ]\n",
      "\n",
      "----------------------------------------\n",
      "Method: SVC (RBF)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [1 2 2]\n",
      "Accuracy score on training data: 45.00 %\n",
      "Intercept: -0.20\n",
      "Coefficient: [ 0.    1.    1.    0.05  1.    0.    0.07  0.72  1.    0.    0.79  1.\n",
      "  1.    1.    1.    1.    1.    1.    1.    1.    0.33  1.    1.    1.\n",
      " -0.    0.    1.    1.    1.    1.    0.    1.    1.    1.    1.    0.\n",
      "  1.    0.05  1.    0.    1.    0.    1.    0.    1.    1.    1.    0.\n",
      "  1.    0.    1.    0.2   1.    1.    0.    0.98  0.    1.    1.    1.\n",
      "  1.    0.    1.    0.35  0.    1.  ]\n",
      "\n",
      "----------------------------------------\n",
      "Method: SVC (Sigmoid)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [0 0 0]\n",
      "Accuracy score on training data: 58.00 %\n",
      "Intercept: 0.72\n",
      "Coefficient: [1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1.]\n",
      "\n",
      "----------------------------------------\n",
      "Method: SVR (Linear)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [0.37059314 1.50405119 2.29306404]\n",
      "Accuracy score on training data: 59.20 %\n",
      "Intercept: -0.08\n",
      "Coefficient: [ 0.12 -0.47 -0.5   0.44  0.62  0.24  0.25 -0.11 -0.15 -0.4  -0.01  0.01\n",
      "  0.27 -0.63 -0.33 -0.17  0.44 -0.09 -0.46 -0.18 -0.19  0.54  0.47  0.01\n",
      " -0.14  0.04 -0.14  0.4   0.48 -0.01 -0.26  0.22  0.01 -0.34 -0.65 -0.4\n",
      " -0.3   0.02  0.63  0.14  0.18 -0.55  0.58 -0.33  0.02  0.01  0.02  0.01\n",
      " -0.59  0.06 -0.32  0.35  0.12 -0.6   0.01  0.17  0.46 -0.25 -0.02  0.12\n",
      "  0.17 -0.12  0.21  0.    0.08  0.32  0.01 -0.29 -0.18 -0.24 -0.86  0.05\n",
      "  0.01  0.69  0.    0.1   0.22  0.53  0.13  0.01 -0.02  0.39 -0.46 -0.01\n",
      "  0.02  0.45 -0.02  0.01 -0.42  0.17  0.17  0.01 -0.03  0.51  0.12 -0.46\n",
      " -0.16 -0.01 -0.01 -0.09]\n",
      "\n",
      "----------------------------------------\n",
      "Method: SVR (Polynomial)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [0.4757017  4.07768808 1.61887249]\n",
      "Accuracy score on training data: 61.52 %\n",
      "Intercept: -0.00\n",
      "Coefficient: [ 0.12 -0.48 -0.5   0.45  0.59  0.26  0.27 -0.14 -0.07 -0.38 -0.01  0.\n",
      "  0.3  -0.63 -0.27 -0.07  0.48 -0.08 -0.41 -0.15 -0.2   0.54  0.45 -0.03\n",
      " -0.04  0.1  -0.15  0.39  0.48 -0.   -0.22  0.22  0.   -0.3  -0.62 -0.34\n",
      " -0.25  0.    0.66  0.14  0.17 -0.51  0.63 -0.35  0.01 -0.02  0.    0.\n",
      " -0.55 -0.   -0.3   0.35  0.05 -0.57  0.    0.18  0.43 -0.19 -0.02  0.12\n",
      "  0.03 -0.15  0.17 -0.12  0.03  0.31  0.   -0.23 -0.17 -0.21 -0.88  0.05\n",
      "  0.    0.76 -0.14  0.07  0.22  0.55  0.13 -0.   -0.01  0.4  -0.45 -0.\n",
      "  0.02  0.44 -0.01  0.   -0.4   0.07  0.19 -0.   -0.04  0.51  0.12 -0.47\n",
      " -0.19 -0.   -0.   -0.17]\n",
      "\n",
      "----------------------------------------\n",
      "Method: SVR (RBF)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [0.46691651 0.4510829  0.44698804]\n",
      "Accuracy score on training data: 63.27 %\n",
      "Intercept: 0.42\n",
      "Coefficient: [ 0.1  -0.5  -0.53  0.42  0.6   0.21  0.24  0.03 -0.03 -0.35 -0.02  0.03\n",
      "  0.26 -0.63 -0.24 -0.04  0.45  0.03 -0.4  -0.14 -0.2   0.52  0.44  0.05\n",
      " -0.03  0.03 -0.15  0.36  0.46 -0.02 -0.17  0.17  0.03 -0.28 -0.66 -0.32\n",
      " -0.22  0.04  0.66  0.04  0.13 -0.53  0.65 -0.36  0.03  0.03  0.05  0.02\n",
      " -0.57 -0.02 -0.28  0.31  0.04 -0.61  0.02  0.07  0.43 -0.09 -0.03  0.03\n",
      " -0.02  0.02  0.09  0.06  0.04  0.28  0.03 -0.18 -0.15 -0.17 -0.87  0.05\n",
      "  0.03  0.8   0.07  0.03  0.17  0.53  0.04  0.03 -0.02  0.36 -0.45  0.\n",
      "  0.04  0.41 -0.02  0.03 -0.41 -0.02  0.13  0.07 -0.04  0.48  0.1  -0.49\n",
      "  0.02 -0.02 -0.02 -0.19]\n",
      "\n",
      "----------------------------------------\n",
      "Method: SVR (Sigmoid)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [ 0.13372817 -0.19424631 -0.20194206]\n",
      "Accuracy score on training data: -82.80 %\n",
      "Intercept: -0.16\n",
      "Coefficient: [-0.39 -0.99 -0.84  0.66  0.64  0.52  0.61  0.3  -0.55 -0.39 -0.46  0.61\n",
      "  0.59 -0.36 -0.43 -0.5   0.48  0.18 -0.41 -0.41 -0.84  0.14  0.66  0.7\n",
      " -0.44  0.57 -0.4   0.01  0.16 -0.45 -0.57  0.4   0.65 -0.4  -0.49 -0.49\n",
      " -0.58  0.67  0.62  0.63  0.45 -0.52  0.51 -1.    0.4   0.68  0.68  0.38\n",
      " -0.45 -0.35 -0.39  0.29  0.28 -0.54  0.54  0.51  0.66 -0.53 -0.55  0.56\n",
      " -0.38  0.6  -0.33  0.71  0.28  0.06  0.26 -0.52 -0.41 -0.65 -0.92  0.67\n",
      "  0.29  0.52  0.71  0.43  0.29  0.26  0.39  0.64 -0.48  0.32 -0.38 -0.51\n",
      "  0.17 -0.06 -0.52  0.42 -0.38 -0.38  0.57  0.7  -0.69  0.04 -0.37 -1.\n",
      "  0.35 -0.42 -0.51 -0.92]\n",
      "\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "# Create number of rows and random x and y matrices\n",
    "m = 100\n",
    "X1 = 2 * np.random.rand(m, 1)\n",
    "X2 = 2 * np.random.rand(m, 1)\n",
    "X = np.column_stack((X1, X2))\n",
    "\n",
    "# Generate continuous target then convert to binary classes (0 and 1) also have low and high thresholds to generate \n",
    "y_continuous = 4 + 3 * X[:, 0] + np.random.randn(m)\n",
    "threshold = np.mean(y_continuous)\n",
    "y_labels = (y_continuous > threshold).astype(int)\n",
    "low_threshold = np.percentile(y_continuous, 33)\n",
    "high_threshold = np.percentile(y_continuous, 66)\n",
    "y_multi = np.zeros(m, dtype=int)\n",
    "y_multi[y_continuous > low_threshold] = 1\n",
    "y_multi[y_continuous > high_threshold] = 2\n",
    "\n",
    "\n",
    "# Test data\n",
    "X_new = np.array([[1, 2], [3, 4], [4, 3]])\n",
    "\n",
    "\n",
    "# we will just test the SVC \n",
    "models = {\n",
    "    \"SVC (Linear)\": SVC(kernel='Linear'),\n",
    "    \"SVC (Polynomial)\": SVC(kernel='Polynomial', gamma=0.5),\n",
    "    \"SVC (RBF)\": SVC(kernel='RBF', gamma=0.5),\n",
    "    \"SVC (Sigmoid)\": SVC(kernel='Sigmoid'),\n",
    "}\n",
    "\n",
    "for name in models:\n",
    "    # Get SVM object\n",
    "    model = models[name]\n",
    "    model.fit(X, y_labels)\n",
    "    # Note: SVC predicts -1 or 1, while y_labels are 0 or 1.\n",
    "    # The score function in the SVC class handles this internally if y_labels is used.\n",
    "    y_pred = model.predict(X_new)\n",
    "    score_train = model.score(X, y_labels) * 100\n",
    "    print(f'Method: {name}')\n",
    "    print(f'Predictions for {X_new.tolist()}: {y_pred}')\n",
    "    print(f'Accuracy score on training data: {score_train:.2f} %')\n",
    "    print(f'Intercept: {model.intercept_:.2f}')\n",
    "    print(f'Coefficient: {np.round(model.coef_, 2)}\\n')\n",
    "    print('-' * 40)\n",
    "\n",
    "# we will just test SVR with multiclass using OVR\n",
    "models = {\n",
    "    \"SVC (Linear)\": SVC(kernel='Linear', decision_function_shape='ovr'),\n",
    "    \"SVC (Polynomial)\": SVC(kernel='Polynomial', gamma=0.5, decision_function_shape='ovr'),\n",
    "    \"SVC (RBF)\": SVC(kernel='RBF', gamma=0.5, decision_function_shape='ovr'),\n",
    "    \"SVC (Sigmoid)\": SVC(kernel='Sigmoid', decision_function_shape='ovr'),\n",
    "}\n",
    "\n",
    "for name in models:\n",
    "    # Get SVM object\n",
    "    model = models[name]\n",
    "    model.fit(X, y_multi)\n",
    "    # Note: SVC predicts -1 or 1, while y_labels are 0 or 1.\n",
    "    # The score function in the SVC class handles this internally if y_labels is used.\n",
    "    y_pred = model.predict(X_new)\n",
    "    score_train = model.score(X, y_labels) * 100  \n",
    "    print(f'Method: {name}')\n",
    "    print(f'Predictions for {X_new.tolist()}: {y_pred}')\n",
    "    print(f'Accuracy score on training data: {score_train:.2f} %')\n",
    "    print(f'Intercept: {model.intercept_:.2f}')\n",
    "    print(f'Coefficient: {np.round(model.coef_, 2)}\\n')\n",
    "    print('-' * 40)\n",
    "\n",
    "# we will just test SVR with multiclass using OVO\n",
    "models = {\n",
    "    \"SVC (Linear)\": SVC(kernel='Linear', decision_function_shape='ovo'),\n",
    "    \"SVC (Polynomial)\": SVC(kernel='Polynomial', gamma=0.5, decision_function_shape='ovo'),\n",
    "    \"SVC (RBF)\": SVC(kernel='RBF', gamma=0.5, decision_function_shape='ovo'),\n",
    "    \"SVC (Sigmoid)\": SVC(kernel='Sigmoid', decision_function_shape='ovo'),\n",
    "}\n",
    "\n",
    "for name in models:\n",
    "    # Get SVM object\n",
    "    model = models[name]\n",
    "    model.fit(X, y_multi)\n",
    "    # Note: SVC predicts -1 or 1, while y_labels are 0 or 1.\n",
    "    # The score function in the SVC class handles this internally if y_labels is used.\n",
    "    y_pred = model.predict(X_new)\n",
    "    score_train = model.score(X, y_labels) * 100\n",
    "    print(f'Method: {name}')\n",
    "    print(f'Predictions for {X_new.tolist()}: {y_pred}')\n",
    "    print(f'Accuracy score on training data: {score_train:.2f} %')\n",
    "    print(f'Intercept: {model.intercept_:.2f}')\n",
    "    print(f'Coefficient: {np.round(model.coef_, 2)}\\n')\n",
    "    print('-' * 40)\n",
    "\n",
    "# we will just test the SVR \n",
    "models = {\n",
    "    \"SVR (Linear)\": SVR(kernel='Linear'),\n",
    "    \"SVR (Polynomial)\": SVR(kernel='Polynomial', gamma=0.5),\n",
    "    \"SVR (RBF)\": SVR(kernel='RBF', gamma=0.5),\n",
    "    \"SVR (Sigmoid)\": SVR(kernel='Sigmoid'),\n",
    "}\n",
    "\n",
    "for name in models:\n",
    "    # Get SVM object\n",
    "    model = models[name]\n",
    "    # Use y_labels for binary, y_multi for multiclass\n",
    "    target = y_labels if \"decision_function_shape\" not in name else y_multi\n",
    "    model.fit(X, target)\n",
    "    y_pred = model.predict(X_new)\n",
    "    score_train = model.score(X, target) * 100\n",
    "    print(f'Method: {name}') \n",
    "    print(f'Predictions for {X_new.tolist()}: {y_pred}')\n",
    "    print(f'Accuracy score on training data: {score_train:.2f} %')\n",
    "    print(f'Intercept: {model.intercept_:.2f}')\n",
    "    print(f'Coefficient: {np.round(model.coef_, 2)}\\n')\n",
    "    print('-' * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
