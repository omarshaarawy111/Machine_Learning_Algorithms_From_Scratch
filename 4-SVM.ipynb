{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f303ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# SVM class for Classification and Regression\n",
    "# Kernal functions for SVM \n",
    "# It will be used for classification and regression \n",
    "# Linear Kernel\n",
    "def linear_kernel(x1, x2):\n",
    "    return np.dot(x1, x2)   \n",
    "\n",
    "# Polynomial Kernel\n",
    "def polynomial_kernel(x1, x2 , gamma=1, degree=3, coef0=1):\n",
    "    return ((gamma * np.dot(x1, x2)) + coef0) ** degree\n",
    "\n",
    "# Radial Basis Function (RBF) Kernel \n",
    "def rbf_kernel(x1, x2, gamma=1):\n",
    "    distance = np.linalg.norm(x1 - x2) ** 2\n",
    "    # Know that gamm = 1 / (2 * sigma^2)      \n",
    "    return np.exp(-gamma * distance)\n",
    "\n",
    "# Sigmoid Kernel\n",
    "def sigmoid_kernel(x1, x2, gamma=0.01, coef0=0):\n",
    "    return np.tanh((gamma * np.dot(x1, x2)) + coef0)\n",
    "\n",
    "# Classification and Regression using SVM\n",
    "# Classification class\n",
    "class SVC():\n",
    "\n",
    "    # Initialization\n",
    "    # Tol is threshold for stopping criteria \n",
    "    def __init__(self, c = 1.0, kernel = 'Linear', degree=3, gamma=1, coef0=1, tol=1e-3, max_iter=1000, decision_function_shape='ovr'):\n",
    "        self.c = c\n",
    "        self.degree = degree\n",
    "        self.gamma = gamma\n",
    "        self.coef0 = coef0\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.decision_function_shape = decision_function_shape\n",
    "        self.models = [] # To store sub-models for multiclass\n",
    "        self.classes = None\n",
    "        \n",
    "        # For each case of kernal is assigned by the retun value of the function to the varaibale kernal and assign the all parameters\n",
    "        # We make varaible as function \n",
    "        if kernel == 'Linear':\n",
    "            self.kernel = lambda x1, x2: linear_kernel(x1, x2)\n",
    "\n",
    "        elif kernel == 'Polynomial':\n",
    "            self.kernel = lambda x1, x2: polynomial_kernel(x1, x2, gamma=self.gamma, degree=self.degree, coef0=self.coef0)    \n",
    "\n",
    "        elif kernel == 'RBF':\n",
    "            self.kernel = lambda x1, x2: rbf_kernel(x1, x2, gamma=self.gamma)\n",
    "\n",
    "        elif kernel == 'Sigmoid':\n",
    "            self.kernel = lambda x1, x2: sigmoid_kernel(x1, x2, gamma=self.gamma, coef0=self.coef0)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unknown kernel.\")    \n",
    "\n",
    "    # Internal helper for binary training (SMO)\n",
    "    def _fit_binary(self, X, y):\n",
    "        m, n = X.shape\n",
    "        theta = np.zeros(m)\n",
    "        b = 0\n",
    "\n",
    "        # Compute the Kernel matrix\n",
    "        K_matrix = np.zeros((m, m))\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "                K_matrix[i, j] = self.kernel(X[i], X[j])   \n",
    "\n",
    "        # SMO Algorithm\n",
    "        for iteration in range(self.max_iter):      \n",
    "            alpha_prev = np.copy(theta)\n",
    "\n",
    "            for i in range(m):\n",
    "                f_xi = np.sum(theta * y * K_matrix[:, i]) + b\n",
    "                E_i = f_xi - y[i]\n",
    "\n",
    "                if (y[i] * E_i < -self.tol and theta[i] < self.c) or (y[i] * E_i > self.tol and theta[i] > 0):\n",
    "                    j = np.random.randint(0, m)\n",
    "                    while j == i:\n",
    "                        j = np.random.randint(0, m)\n",
    "\n",
    "                    f_xj = np.sum(theta * y * K_matrix[:, j]) + b\n",
    "                    E_j = f_xj - y[j]\n",
    "\n",
    "                    alpha_i_old, alpha_j_old = theta[i], theta[j]\n",
    "\n",
    "                    if y[i] != y[j]:\n",
    "                        L, H = max(0, alpha_j_old - alpha_i_old), min(self.c, self.c + alpha_j_old - alpha_i_old)\n",
    "                    else:\n",
    "                        L, H = max(0, alpha_i_old + alpha_j_old - self.c), min(self.c, alpha_i_old + alpha_j_old)\n",
    "\n",
    "                    if L == H: continue\n",
    "\n",
    "                    eta = 2.0 * K_matrix[i, j] - K_matrix[i, i] - K_matrix[j, j]\n",
    "                    if eta >= 0: continue\n",
    "\n",
    "                    theta[j] -= (y[j] * (E_i - E_j)) / eta\n",
    "                    theta[j] = np.clip(theta[j], L, H)\n",
    "\n",
    "                    if abs(theta[j] - alpha_j_old) < 1e-5: continue\n",
    "\n",
    "                    theta[i] += y[i] * y[j] * (alpha_j_old - theta[j])\n",
    "\n",
    "                    b1 = b - E_i - y[i] * (theta[i] - alpha_i_old) * K_matrix[i, i] - y[j] * (theta[j] - alpha_j_old) * K_matrix[i, j]   \n",
    "                    b2 = b - E_j - y[i] * (theta[i] - alpha_i_old) * K_matrix[i, j] - y[j] * (theta[j] - alpha_j_old) * K_matrix[j, j]\n",
    "\n",
    "                    if 0 < theta[i] < self.c: b = b1\n",
    "                    elif 0 < theta[j] < self.c: b = b2\n",
    "                    else: b = (b1 + b2) / 2\n",
    "\n",
    "            if np.linalg.norm(theta - alpha_prev) < self.tol:\n",
    "                break\n",
    "        \n",
    "        return {\"theta\": theta, \"b\": b, \"X\": X, \"y\": y}\n",
    "    \n",
    "    # Fit \n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        n_classes = len(self.classes)\n",
    "        self.models = []\n",
    "\n",
    "        if n_classes <= 2:\n",
    "            binary_y = np.where(y == self.classes[0], -1, 1)\n",
    "            self.models.append(self._fit_binary(X, binary_y))\n",
    "            \n",
    "        elif self.decision_function_shape == 'ovr':\n",
    "            # One vs Rest\n",
    "            \n",
    "            for c in self.classes:\n",
    "                binary_y = np.where(y == c, 1, -1)\n",
    "                self.models.append(self._fit_binary(X, binary_y))\n",
    "\n",
    "        elif self.decision_function_shape == 'ovo':\n",
    "            # One vs One\n",
    "            \n",
    "            for i in range(n_classes):\n",
    "                for j in range(i + 1, n_classes):\n",
    "                    idx = np.where((y == self.classes[i]) | (y == self.classes[j]))\n",
    "                    X_sub, y_sub = X[idx], y[idx]\n",
    "                    binary_y = np.where(y_sub == self.classes[i], 1, -1)\n",
    "                    model = self._fit_binary(X_sub, binary_y)\n",
    "                    model['cls_pair'] = (self.classes[i], self.classes[j])\n",
    "                    self.models.append(model)\n",
    "\n",
    "    # Decision function for a single model\n",
    "    def _get_score(self, X, model):\n",
    "        scores = []\n",
    "        for x in X:\n",
    "            score = np.sum(model['theta'] * model['y'] * [self.kernel(x_tr, x) for x_tr in model['X']]) + model['b']\n",
    "            scores.append(score)\n",
    "        return np.array(scores)\n",
    "\n",
    "    # Predict             \n",
    "    def predict(self, X):\n",
    "        if len(self.classes) <= 2:\n",
    "            scores = self._get_score(X, self.models[0])\n",
    "            return np.where(scores >= 0, self.classes[1], self.classes[0])\n",
    "\n",
    "        if self.decision_function_shape == 'ovr':\n",
    "            # Highest confidence wins\n",
    "            all_scores = np.array([self._get_score(X, m) for m in self.models])\n",
    "            return self.classes[np.argmax(all_scores, axis=0)]\n",
    "\n",
    "        elif self.decision_function_shape == 'ovo':\n",
    "            # Voting system\n",
    "            votes = np.zeros((len(X), len(self.classes)))\n",
    "            for m in self.models:\n",
    "                scores = self._get_score(X, m)\n",
    "                preds = np.where(scores >= 0, m['cls_pair'][0], m['cls_pair'][1])\n",
    "                for idx, p in enumerate(preds):\n",
    "                    votes[idx, np.where(self.classes == p)[0][0]] += 1\n",
    "            return self.classes[np.argmax(votes, axis=1)]\n",
    "\n",
    "    # Score \n",
    "    def score(self, X_new, y):\n",
    "        # Return accuracy score of the model\n",
    "        y_pred = self.predict(X_new)\n",
    "        return np.mean(y_pred == y) \n",
    "\n",
    "# Regression remains largely the same but usually doesn't use OVO/OVR\n",
    "class SVR():\n",
    "    def __init__(self, c=1.0, epsilon=0.1, kernel='Linear', degree=3, gamma=1, coef0=1, lr=0.001, max_iter=1000):\n",
    "        self.c = c\n",
    "        self.epsilon = epsilon\n",
    "        self.degree = degree\n",
    "        self.gamma = gamma\n",
    "        self.coef0 = coef0\n",
    "        self.lr = lr\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "        if kernel == 'Linear':\n",
    "            self.kernel = lambda x1, x2: linear_kernel(x1, x2)\n",
    "        elif kernel == 'Polynomial':\n",
    "            self.kernel = lambda x1, x2: polynomial_kernel(x1, x2, gamma=self.gamma, degree=self.degree, coef0=self.coef0)\n",
    "        elif kernel == 'RBF':\n",
    "            self.kernel = lambda x1, x2: rbf_kernel(x1, x2, gamma=self.gamma)\n",
    "        elif kernel == 'Sigmoid':\n",
    "            self.kernel = lambda x1, x2: sigmoid_kernel(x1, x2, gamma=self.gamma, coef0=self.coef0)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown kernel.\")\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        m = len(X)\n",
    "        self.alpha = np.zeros(m)\n",
    "        self.b = 0\n",
    "\n",
    "        self.K_matrix = np.zeros((m, m))\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "                self.K_matrix[i, j] = self.kernel(X[i], X[j])\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            for i in range(m):\n",
    "                pred = np.sum(self.alpha * self.K_matrix[:, i]) + self.b\n",
    "                error = pred - self.y[i]\n",
    "                if abs(error) > self.epsilon:\n",
    "                    self.alpha[i] -= self.lr * error\n",
    "                    self.alpha[i] = np.clip(self.alpha[i], -self.c, self.c)\n",
    "                    self.b -= self.lr * error\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            pred = np.sum(self.alpha * [self.kernel(x_tr, x) for x_tr in self.X]) + self.b\n",
    "            predictions.append(pred)\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def score(self, X_new, y):\n",
    "        y_pred = self.predict(X_new)\n",
    "        ss_total = np.sum((y - np.mean(y)) ** 2)\n",
    "        ss_residual = np.sum((y - y_pred) ** 2)\n",
    "        return 1 - ss_residual / ss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51af1121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: SVC (Linear)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [1 1 1]\n",
      "Accuracy score on training data: 82.00 %\n",
      "----------------------------------------\n",
      "Method: SVC (Polynomial)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [1 1 1]\n",
      "Accuracy score on training data: 84.00 %\n",
      "----------------------------------------\n",
      "Method: SVC (RBF)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [1 1 0]\n",
      "Accuracy score on training data: 84.00 %\n",
      "----------------------------------------\n",
      "Method: SVC (Sigmoid)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [0 0 0]\n",
      "Accuracy score on training data: 56.00 %\n",
      "----------------------------------------\n",
      "Method: SVC (Linear)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [2 2 2]\n",
      "Accuracy score on training data: 39.00 %\n",
      "----------------------------------------\n",
      "Method: SVC (Polynomial)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [1 2 2]\n",
      "Accuracy score on training data: 43.00 %\n",
      "----------------------------------------\n",
      "Method: SVC (RBF)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [2 2 2]\n",
      "Accuracy score on training data: 37.00 %\n",
      "----------------------------------------\n",
      "Method: SVC (Sigmoid)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [0 0 0]\n",
      "Accuracy score on training data: 34.00 %\n",
      "----------------------------------------\n",
      "Method: SVC (Linear)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [1 2 2]\n",
      "Accuracy score on training data: 52.00 %\n",
      "----------------------------------------\n",
      "Method: SVC (Polynomial)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [1 2 2]\n",
      "Accuracy score on training data: 53.00 %\n",
      "----------------------------------------\n",
      "Method: SVC (RBF)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [1 0 0]\n",
      "Accuracy score on training data: 56.00 %\n",
      "----------------------------------------\n",
      "Method: SVC (Sigmoid)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [0 0 0]\n",
      "Accuracy score on training data: 44.00 %\n",
      "----------------------------------------\n",
      "Method: SVR (Linear)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [0.54925732 1.86487585 2.59592775]\n",
      "Accuracy score on training data: 55.07 %\n",
      "----------------------------------------\n",
      "Method: SVR (Polynomial)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [ 0.6449862   1.5024853  -1.30212731]\n",
      "Accuracy score on training data: 57.13 %\n",
      "----------------------------------------\n",
      "Method: SVR (RBF)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [0.59127873 0.36467847 0.35886397]\n",
      "Accuracy score on training data: 58.18 %\n",
      "----------------------------------------\n",
      "Method: SVR (Sigmoid)\n",
      "Predictions for [[1, 2], [3, 4], [4, 3]]: [-0.06737388 -0.48721155 -0.48668158]\n",
      "Accuracy score on training data: -135.71 %\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "# Create number of rows and random x and y matrices\n",
    "m = 100\n",
    "X1 = 2 * np.random.rand(m, 1)\n",
    "X2 = 2 * np.random.rand(m, 1)\n",
    "X = np.column_stack((X1, X2))\n",
    "\n",
    "# Generate continuous target then convert to binary classes (0 and 1) also have low and high thresholds to generate \n",
    "y_continuous = 4 + 3 * X[:, 0] + np.random.randn(m)\n",
    "threshold = np.mean(y_continuous)\n",
    "y_labels = (y_continuous > threshold).astype(int)\n",
    "low_threshold = np.percentile(y_continuous, 33)\n",
    "high_threshold = np.percentile(y_continuous, 66)\n",
    "y_multi = np.zeros(m, dtype=int)\n",
    "y_multi[y_continuous > low_threshold] = 1\n",
    "y_multi[y_continuous > high_threshold] = 2\n",
    "\n",
    "\n",
    "# Test data\n",
    "X_new = np.array([[1, 2], [3, 4], [4, 3]])\n",
    "\n",
    "\n",
    "# we will just test the SVC \n",
    "models = {\n",
    "    \"SVC (Linear)\": SVC(kernel='Linear'),\n",
    "    \"SVC (Polynomial)\": SVC(kernel='Polynomial', gamma=0.5),\n",
    "    \"SVC (RBF)\": SVC(kernel='RBF', gamma=0.5),\n",
    "    \"SVC (Sigmoid)\": SVC(kernel='Sigmoid'),\n",
    "}\n",
    "\n",
    "for name in models:\n",
    "    model = models[name]\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X, y_labels)\n",
    "    \n",
    "    # Predictions\n",
    "    # Note: SVC predicts -1 or 1, while y_labels are 0 or 1.\n",
    "    # The score function in the SVC class handles this internally if y_labels is used.\n",
    "    y_pred = model.predict(X_new)\n",
    "    \n",
    "    # Accuracy score\n",
    "    # Multiply by 100 to show as a percentage as per your print statement\n",
    "    score_train = model.score(X, y_labels) * 100\n",
    "    \n",
    "    print(f'Method: {name}')\n",
    "    print(f'Predictions for {X_new.tolist()}: {y_pred}')\n",
    "    print(f'Accuracy score on training data: {score_train:.2f} %')\n",
    "    print('-' * 40)\n",
    "\n",
    "# we will just test SVR with multiclass using OVR\n",
    "models = {\n",
    "    \"SVC (Linear)\": SVC(kernel='Linear', decision_function_shape='ovr'),\n",
    "    \"SVC (Polynomial)\": SVC(kernel='Polynomial', gamma=0.5, decision_function_shape='ovr'),\n",
    "    \"SVC (RBF)\": SVC(kernel='RBF', gamma=0.5, decision_function_shape='ovr'),\n",
    "    \"SVC (Sigmoid)\": SVC(kernel='Sigmoid', decision_function_shape='ovr'),\n",
    "}\n",
    "\n",
    "for name in models:\n",
    "    model = models[name]\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X, y_multi)\n",
    "    \n",
    "    # Predictions\n",
    "    # Note: SVC predicts -1 or 1, while y_labels are 0 or 1.\n",
    "    # The score function in the SVC class handles this internally if y_labels is used.\n",
    "    y_pred = model.predict(X_new)\n",
    "    \n",
    "    # Accuracy score\n",
    "    # Multiply by 100 to show as a percentage as per your print statement\n",
    "    score_train = model.score(X, y_labels) * 100\n",
    "    \n",
    "    print(f'Method: {name}')\n",
    "    print(f'Predictions for {X_new.tolist()}: {y_pred}')\n",
    "    print(f'Accuracy score on training data: {score_train:.2f} %')\n",
    "    print('-' * 40)\n",
    "\n",
    "# we will just test SVR with multiclass using OVO\n",
    "models = {\n",
    "    \"SVC (Linear)\": SVC(kernel='Linear', decision_function_shape='ovo'),\n",
    "    \"SVC (Polynomial)\": SVC(kernel='Polynomial', gamma=0.5, decision_function_shape='ovo'),\n",
    "    \"SVC (RBF)\": SVC(kernel='RBF', gamma=0.5, decision_function_shape='ovo'),\n",
    "    \"SVC (Sigmoid)\": SVC(kernel='Sigmoid', decision_function_shape='ovo'),\n",
    "}\n",
    "\n",
    "for name in models:\n",
    "    model = models[name]\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X, y_multi)\n",
    "    \n",
    "    # Predictions\n",
    "    # Note: SVC predicts -1 or 1, while y_labels are 0 or 1.\n",
    "    # The score function in the SVC class handles this internally if y_labels is used.\n",
    "    y_pred = model.predict(X_new)\n",
    "    \n",
    "    # Accuracy score\n",
    "    # Multiply by 100 to show as a percentage as per your print statement\n",
    "    score_train = model.score(X, y_labels) * 100\n",
    "    \n",
    "    print(f'Method: {name}')\n",
    "    print(f'Predictions for {X_new.tolist()}: {y_pred}')\n",
    "    print(f'Accuracy score on training data: {score_train:.2f} %')\n",
    "    print('-' * 40)\n",
    "\n",
    "# we will just test the SVR \n",
    "models = {\n",
    "    \"SVR (Linear)\": SVR(kernel='Linear'),\n",
    "    \"SVR (Polynomial)\": SVR(kernel='Polynomial', gamma=0.5),\n",
    "    \"SVR (RBF)\": SVR(kernel='RBF', gamma=0.5),\n",
    "    \"SVR (Sigmoid)\": SVR(kernel='Sigmoid'),\n",
    "}\n",
    "\n",
    "for name in models:\n",
    "    model = models[name]\n",
    "    \n",
    "    # Use y_labels for binary, y_multi for multiclass\n",
    "    target = y_labels if \"decision_function_shape\" not in name else y_multi\n",
    "    model.fit(X, target)\n",
    "    \n",
    "    y_pred = model.predict(X_new)\n",
    "    score_train = model.score(X, target) * 100\n",
    "    \n",
    "    print(f'Method: {name}') \n",
    "    print(f'Predictions for {X_new.tolist()}: {y_pred}')\n",
    "    print(f'Accuracy score on training data: {score_train:.2f} %')\n",
    "    print('-' * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
